// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_CUSTOMCALLCONFIG_BYTEPS_XLA_WIRE_H_
#define FLATBUFFERS_GENERATED_CUSTOMCALLCONFIG_BYTEPS_XLA_WIRE_H_

#include "flatbuffers/flatbuffers.h"

namespace byteps {
namespace xla {
namespace wire {

struct TensorShape;
struct TensorShapeBuilder;

struct CustomCallConfig;
struct CustomCallConfigBuilder;

}  // namespace wire
}  // namespace xla

namespace common {
namespace wire {

enum DataType : int8_t {
  DataType_BYTEPS_UINT8 = 0,
  DataType_BYTEPS_INT8 = 1,
  DataType_BYTEPS_UINT16 = 2,
  DataType_BYTEPS_INT16 = 3,
  DataType_BYTEPS_INT32 = 4,
  DataType_BYTEPS_INT64 = 5,
  DataType_BYTEPS_FLOAT16 = 6,
  DataType_BYTEPS_FLOAT32 = 7,
  DataType_BYTEPS_FLOAT64 = 8,
  DataType_BYTEPS_BOOL = 9,
  DataType_MIN = DataType_BYTEPS_UINT8,
  DataType_MAX = DataType_BYTEPS_BOOL
};

inline const DataType (&EnumValuesDataType())[10] {
  static const DataType values[] = {
    DataType_BYTEPS_UINT8,
    DataType_BYTEPS_INT8,
    DataType_BYTEPS_UINT16,
    DataType_BYTEPS_INT16,
    DataType_BYTEPS_INT32,
    DataType_BYTEPS_INT64,
    DataType_BYTEPS_FLOAT16,
    DataType_BYTEPS_FLOAT32,
    DataType_BYTEPS_FLOAT64,
    DataType_BYTEPS_BOOL
  };
  return values;
}

inline const char * const *EnumNamesDataType() {
  static const char * const names[11] = {
    "BYTEPS_UINT8",
    "BYTEPS_INT8",
    "BYTEPS_UINT16",
    "BYTEPS_INT16",
    "BYTEPS_INT32",
    "BYTEPS_INT64",
    "BYTEPS_FLOAT16",
    "BYTEPS_FLOAT32",
    "BYTEPS_FLOAT64",
    "BYTEPS_BOOL",
    nullptr
  };
  return names;
}

inline const char *EnumNameDataType(DataType e) {
  if (flatbuffers::IsOutRange(e, DataType_BYTEPS_UINT8, DataType_BYTEPS_BOOL)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesDataType()[index];
}

}  // namespace wire
}  // namespace common

namespace xla {
namespace wire {

struct TensorShape FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef TensorShapeBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_DIMS = 4
  };
  const flatbuffers::Vector<int64_t> *dims() const {
    return GetPointer<const flatbuffers::Vector<int64_t> *>(VT_DIMS);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_DIMS) &&
           verifier.VerifyVector(dims()) &&
           verifier.EndTable();
  }
};

struct TensorShapeBuilder {
  typedef TensorShape Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_dims(flatbuffers::Offset<flatbuffers::Vector<int64_t>> dims) {
    fbb_.AddOffset(TensorShape::VT_DIMS, dims);
  }
  explicit TensorShapeBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<TensorShape> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<TensorShape>(end);
    return o;
  }
};

inline flatbuffers::Offset<TensorShape> CreateTensorShape(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::Vector<int64_t>> dims = 0) {
  TensorShapeBuilder builder_(_fbb);
  builder_.add_dims(dims);
  return builder_.Finish();
}

inline flatbuffers::Offset<TensorShape> CreateTensorShapeDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const std::vector<int64_t> *dims = nullptr) {
  auto dims__ = dims ? _fbb.CreateVector<int64_t>(*dims) : 0;
  return byteps::xla::wire::CreateTensorShape(
      _fbb,
      dims__);
}

struct CustomCallConfig FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef CustomCallConfigBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_TENSOR_NAME = 4,
    VT_TENSOR_TYPE = 6,
    VT_INPUT_SHAPES = 8,
    VT_OUTPUT_SHAPES = 10,
    VT_REDUCE_OP = 12
  };
  const flatbuffers::String *tensor_name() const {
    return GetPointer<const flatbuffers::String *>(VT_TENSOR_NAME);
  }
  byteps::common::wire::DataType tensor_type() const {
    return static_cast<byteps::common::wire::DataType>(GetField<int8_t>(VT_TENSOR_TYPE, 0));
  }
  const flatbuffers::Vector<flatbuffers::Offset<byteps::xla::wire::TensorShape>> *input_shapes() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<byteps::xla::wire::TensorShape>> *>(VT_INPUT_SHAPES);
  }
  const flatbuffers::Vector<flatbuffers::Offset<byteps::xla::wire::TensorShape>> *output_shapes() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<byteps::xla::wire::TensorShape>> *>(VT_OUTPUT_SHAPES);
  }
  int32_t reduce_op() const {
    return GetField<int32_t>(VT_REDUCE_OP, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_TENSOR_NAME) &&
           verifier.VerifyString(tensor_name()) &&
           VerifyField<int8_t>(verifier, VT_TENSOR_TYPE) &&
           VerifyOffset(verifier, VT_INPUT_SHAPES) &&
           verifier.VerifyVector(input_shapes()) &&
           verifier.VerifyVectorOfTables(input_shapes()) &&
           VerifyOffset(verifier, VT_OUTPUT_SHAPES) &&
           verifier.VerifyVector(output_shapes()) &&
           verifier.VerifyVectorOfTables(output_shapes()) &&
           VerifyField<int32_t>(verifier, VT_REDUCE_OP) &&
           verifier.EndTable();
  }
};

struct CustomCallConfigBuilder {
  typedef CustomCallConfig Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_tensor_name(flatbuffers::Offset<flatbuffers::String> tensor_name) {
    fbb_.AddOffset(CustomCallConfig::VT_TENSOR_NAME, tensor_name);
  }
  void add_tensor_type(byteps::common::wire::DataType tensor_type) {
    fbb_.AddElement<int8_t>(CustomCallConfig::VT_TENSOR_TYPE, static_cast<int8_t>(tensor_type), 0);
  }
  void add_input_shapes(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<byteps::xla::wire::TensorShape>>> input_shapes) {
    fbb_.AddOffset(CustomCallConfig::VT_INPUT_SHAPES, input_shapes);
  }
  void add_output_shapes(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<byteps::xla::wire::TensorShape>>> output_shapes) {
    fbb_.AddOffset(CustomCallConfig::VT_OUTPUT_SHAPES, output_shapes);
  }
  void add_reduce_op(int32_t reduce_op) {
    fbb_.AddElement<int32_t>(CustomCallConfig::VT_REDUCE_OP, reduce_op, 0);
  }
  explicit CustomCallConfigBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<CustomCallConfig> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<CustomCallConfig>(end);
    return o;
  }
};

inline flatbuffers::Offset<CustomCallConfig> CreateCustomCallConfig(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> tensor_name = 0,
    byteps::common::wire::DataType tensor_type = byteps::common::wire::DataType_BYTEPS_UINT8,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<byteps::xla::wire::TensorShape>>> input_shapes = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<byteps::xla::wire::TensorShape>>> output_shapes = 0,
    int32_t reduce_op = 0) {
  CustomCallConfigBuilder builder_(_fbb);
  builder_.add_reduce_op(reduce_op);
  builder_.add_output_shapes(output_shapes);
  builder_.add_input_shapes(input_shapes);
  builder_.add_tensor_name(tensor_name);
  builder_.add_tensor_type(tensor_type);
  return builder_.Finish();
}

inline flatbuffers::Offset<CustomCallConfig> CreateCustomCallConfigDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *tensor_name = nullptr,
    byteps::common::wire::DataType tensor_type = byteps::common::wire::DataType_BYTEPS_UINT8,
    const std::vector<flatbuffers::Offset<byteps::xla::wire::TensorShape>> *input_shapes = nullptr,
    const std::vector<flatbuffers::Offset<byteps::xla::wire::TensorShape>> *output_shapes = nullptr,
    int32_t reduce_op = 0) {
  auto tensor_name__ = tensor_name ? _fbb.CreateString(tensor_name) : 0;
  auto input_shapes__ = input_shapes ? _fbb.CreateVector<flatbuffers::Offset<byteps::xla::wire::TensorShape>>(*input_shapes) : 0;
  auto output_shapes__ = output_shapes ? _fbb.CreateVector<flatbuffers::Offset<byteps::xla::wire::TensorShape>>(*output_shapes) : 0;
  return byteps::xla::wire::CreateCustomCallConfig(
      _fbb,
      tensor_name__,
      tensor_type,
      input_shapes__,
      output_shapes__,
      reduce_op);
}

}  // namespace wire
}  // namespace xla
}  // namespace byteps

#endif  // FLATBUFFERS_GENERATED_CUSTOMCALLCONFIG_BYTEPS_XLA_WIRE_H_
